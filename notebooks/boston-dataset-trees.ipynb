{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boston house-prices prediction with decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sys\n",
    "from sklearn.datasets import load_boston\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "from models.decision_tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from models.linear_regression import LinearRegression\n",
    "from utils.visualization import plot_decision_boundary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the dataset\n",
    "\n",
    "The Boston house-prices prediction dataset housing values in suburbs of Boston, each instance is described with 14 attributes, 13 of them are use for prediction, the remaining one, MEDV(Median value of owner occupied homes in $1000's) is the target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load an partition the data\n",
    "(X, y) = load_boston(return_X_y=True)\n",
    "\n",
    "perm = np.random.permutation(X.shape[0])\n",
    "pivot = int(X.shape[0]*0.7)\n",
    "x_train, y_train = X[:pivot, :], y[:pivot]\n",
    "x_test, y_test = X[pivot:, :], y[pivot:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a baseline\n",
    "\n",
    "To asses the quality of the model we may compare its perfromance against that of a simple baseline model, for instance Linear Regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE on the train set: 3.00\n",
      "RMSE on the holdout set: 23.39\n"
     ]
    }
   ],
   "source": [
    "# Create and fit baseline model\n",
    "baseline = LinearRegression()\n",
    "baseline.fit(x_train, y_train)\n",
    "\n",
    "# Compute metrics on trainig and test set\n",
    "rmse_train = np.sqrt(np.mean(np.square(baseline.predict(x_train)-y_train)))\n",
    "y_hat = baseline.predict(x_test)\n",
    "rmse = np.sqrt(np.mean(np.square(y_hat-y_test)))\n",
    "\n",
    "print(\"RMSE on the train set: %.2f\" % rmse_train)\n",
    "print(\"RMSE on the validation set: %.2f\" % rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now our benchmark to beat is a RMSE of 23.39, anything performing worse than that it's not worth it since the simple baseline is able to beat it.\n",
    "\n",
    "To fit a decision tree we have to do some hyperparameter selection. We have to set a maximum depth and a minimum impurity. Let's first start with an educated guess to asses the model selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE on the train set: 2.36\n",
      "RMSE on the holdout set: 6.93\n"
     ]
    }
   ],
   "source": [
    "# Create and fit a tree\n",
    "tree = DecisionTreeRegressor(max_depth=5, min_impurity=1)\n",
    "tree.fit(X=x_train, y=y_train)\n",
    "rmse_train = np.sqrt(np.mean(np.square(tree.predict(x_train)-y_train)))\n",
    "\n",
    "y_hat = tree.predict(x_test)\n",
    "rmse = np.sqrt(np.mean(np.square(y_hat-y_test)))\n",
    "\n",
    "print(\"RMSE on the train set: %.2f\" % rmse_train)\n",
    "print(\"RMSE on the validation set: %.2f\" % rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improving the model\n",
    "\n",
    "The new model is clearly able to outperform the baseline. But maybe we can improve it with hyperparameter search. Due to the small size of the dataset the size of the validation set might not be enough to discriminate with confidence between similar models performance. We may use cross-validation to overcome this problem.\n",
    "\n",
    "### Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate(model, k):\n",
    "    X_fold = X\n",
    "    y_fold = y\n",
    "    pivot = int(X_fold.shape[0]/k)\n",
    "    cum_rmse = 0\n",
    "    for _ in range(k):\n",
    "        # Always take firt fold as test\n",
    "        x_test, y_test = X_fold[:pivot, :], y_fold[:pivot]\n",
    "        x_train, y_train = X_fold[pivot:, :], y_fold[pivot:]\n",
    "        \n",
    "        # fit the model\n",
    "        model.fit(X=x_train, y=y_train)\n",
    "        y_hat = model.predict(x_test)\n",
    "        \n",
    "        cum_rmse += np.sqrt(np.mean(np.square(y_hat-y_test)))\n",
    "        \n",
    "        X_fold = np.concatenate((x_train, x_test))\n",
    "        y_fold = np.concatenate((y_train, y_test))\n",
    "        \n",
    "    return cum_rmse/k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.2953829714342975"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_validate(tree, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
