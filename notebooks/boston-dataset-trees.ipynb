{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boston house-prices prediction with decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import itertools\n",
    "import sys\n",
    "from sklearn.datasets import load_boston\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "from models.decision_tree import DecisionTreeRegressor\n",
    "from models.linear_regression import LinearRegression\n",
    "from models.ensemble import BaggingRegressor, GradientBoostingRegressor\n",
    "from utils.visualization import plot_decision_boundary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the dataset\n",
    "\n",
    "The Boston house-prices prediction dataset housing values in suburbs of Boston, each instance is described with 14 attributes, 13 of them are use for prediction, the remaining one, MEDV(Median value of owner occupied homes in $1000's) is the target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load an partition the data\n",
    "(X, y) = load_boston(return_X_y=True)\n",
    "\n",
    "perm = np.random.permutation(X.shape[0])\n",
    "pivot = int(X.shape[0]*0.7)\n",
    "x_train, y_train = X[:pivot, :], y[:pivot]\n",
    "x_test, y_test = X[pivot:, :], y[pivot:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a baseline\n",
    "\n",
    "To asses the quality of the model we may compare its perfromance against that of a simple baseline model, for instance Linear Regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE on the train set: 3.00\n",
      "RMSE on the validation set: 23.35\n"
     ]
    }
   ],
   "source": [
    "# Create and fit baseline model\n",
    "baseline = LinearRegression()\n",
    "baseline.fit(x_train, y_train)\n",
    "\n",
    "# Compute metrics on training and test set\n",
    "rmse_train = np.sqrt(np.mean(np.square(baseline.predict(x_train)-y_train)))\n",
    "y_hat = baseline.predict(x_test)\n",
    "rmse = np.sqrt(np.mean(np.square(y_hat-y_test)))\n",
    "\n",
    "print(\"RMSE on the train set: %.2f\" % rmse_train)\n",
    "print(\"RMSE on the validation set: %.2f\" % rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now our benchmark to beat is a RMSE of 23.39, anything performing worse than that it's not worth it since the simple baseline is able to beat it.\n",
    "\n",
    "To fit a decision tree we have to do some hyperparameter selection. We have to set a maximum depth and a minimum impurity. Let's first start with an educated guess to asses the model selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE on the train set: 1.97\n",
      "RMSE on the validation set: 6.92\n"
     ]
    }
   ],
   "source": [
    "# Create and fit a tree\n",
    "tree = DecisionTreeRegressor(max_depth=6, min_impurity=1)\n",
    "tree.fit(X=x_train, y=y_train)\n",
    "rmse_train = np.sqrt(np.mean(np.square(tree.predict(x_train)-y_train)))\n",
    "\n",
    "y_hat = tree.predict(x_test)\n",
    "rmse = np.sqrt(np.mean(np.square(y_hat-y_test)))\n",
    "\n",
    "print(\"RMSE on the train set: %.2f\" % rmse_train)\n",
    "print(\"RMSE on the validation set: %.2f\" % rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improving the model\n",
    "\n",
    "The new model is clearly able to outperform the baseline. But maybe we can improve it with hyperparameter search. Due to the small size of the dataset the size of the validation set might not be enough to discriminate with confidence between similar models performance. We may use cross-validation to overcome this problem.\n",
    "\n",
    "### Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate(model, k):\n",
    "    X_fold = X\n",
    "    y_fold = y\n",
    "    pivot = int(X_fold.shape[0]/k)\n",
    "    cum_rmse = 0\n",
    "    for _ in range(k):\n",
    "        # Always take firt fold as test\n",
    "        x_test, y_test = X_fold[:pivot, :], y_fold[:pivot]\n",
    "        x_train, y_train = X_fold[pivot:, :], y_fold[pivot:]\n",
    "        \n",
    "        # fit the model\n",
    "        model.fit(X=x_train, y=y_train)\n",
    "        y_hat = model.predict(x_test)\n",
    "        \n",
    "        cum_rmse += np.sqrt(np.mean(np.square(y_hat-y_test)))\n",
    "        \n",
    "        X_fold = np.concatenate((x_train, x_test))\n",
    "        y_fold = np.concatenate((y_train, y_test))\n",
    "        \n",
    "    return cum_rmse/k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid search over hyperparameter selection\n",
    "\n",
    "Iterate over possible combinations of hyperparameter values to find the better one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found better hyperparameter selection, depth=4, impuriy=0.01. New rmse: 5.823268478476467\n",
      "Found better hyperparameter selection, depth=6, impuriy=0.01. New rmse: 5.464568660983798\n"
     ]
    }
   ],
   "source": [
    "# Initialize best tree with the previous one\n",
    "best_tree = tree\n",
    "best_rmse = rmse\n",
    "best_hyperparams = (6, 1)\n",
    "\n",
    "# Define grid search\n",
    "depths = [4, 6, 8]\n",
    "impurities = [0.01, 0.1, 1]\n",
    "\n",
    "for depth, impurity in itertools.product(depths, impurities):\n",
    "    curr_tree = DecisionTreeRegressor(max_depth=depth, min_impurity=impurity)\n",
    "    curr_rmse = cross_validate(curr_tree, 5)\n",
    "    if curr_rmse < best_rmse:\n",
    "        print(\"Found better hyperparameter selection, depth={}, impuriy={}. New rmse: {}\".format(depth, impurity, curr_rmse))\n",
    "        best_tree = curr_tree\n",
    "        best_rmse = curr_rmse\n",
    "        best_hyperparams = (depth, impurity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble\n",
    "\n",
    "### Bagging\n",
    "To improve the model further we can use a bunch of trees instead of a single one. Each tree is trained on a slightly different dataset. This datasets are random samples with replacement of the original dataset. This is known as the bootstrap, a technique known to reduce the variance of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation rmse: 4.64\n"
     ]
    }
   ],
   "source": [
    "# Create the model\n",
    "base_tree = DecisionTreeRegressor(max_depth=best_hyperparams[0], min_impurity=best_hyperparams[1])\n",
    "bag_trees = BaggingRegressor(base_tree, n_models=50)\n",
    "\n",
    "# Validate\n",
    "rmse = cross_validate(bag_trees, 5)\n",
    "print(\"Cross-Validation rmse: %.2f\" % rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest\n",
    "\n",
    "The idea behind bagging is that a bunch of simple but uncorrelated classifiers will tend to agree on their correct predictions but answer more randomly on their incorrect ones. However if a small subset of the features is highly correlated with the output then trees in the bag will tend to based their decision on this subset of features leading to more correlated trees. Random forest brings the idea of bagging into the trees with what is sometimes called \"feature bagging\". At each split the tree looks only into some random subset of the features, uncorrelating the trees. The size of this subset is also a hyperparameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation rmse: 4.37\n"
     ]
    }
   ],
   "source": [
    "# Create the model specifying `p`, size of the subset of features to consider at each split\n",
    "base_tree = DecisionTreeRegressor(max_depth=best_hyperparams[0], min_impurity=best_hyperparams[1], p=0.5)\n",
    "random_forest = BaggingRegressor(base_tree, n_models=50)\n",
    "\n",
    "# Validate\n",
    "rmse = cross_validate(random_forest, 5)\n",
    "print(\"Cross-Validation rmse: %.2f\" % rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient boosting\n",
    "Learn to predict the errors of the previous model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model\n",
    "base_tree = DecisionTreeRegressor(max_depth=3)\n",
    "boosted_trees = GradientBoostingRegressor(base_tree, learning_rate=0.05, max_models=500)\n",
    "\n",
    "# Validate\n",
    "rmse = cross_validate(boosted_trees, 5)\n",
    "print(\"Cross-Validation rmse: %.2f\" % rmse)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
