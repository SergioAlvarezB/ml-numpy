{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Breast cancer detection with decision trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import itertools\n",
    "import sys\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "from models.decision_tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from models.logistic_regression import LogisticRegression\n",
    "from models.ensemble import BaggingClassifier, GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# Reproducibility.\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data \n",
    "The breast cancer dataset contains 30 features corresponding to the mean, standard error, and worst case, of 10 different measures, which in order they are: \n",
    "\n",
    "* radius (mean of distances from center to points on the perimeter)\n",
    "* texture (standard deviation of gray-scale values)\n",
    "* perimeter\n",
    "* area\n",
    "* smoothness (local variation in radius lengths)\n",
    "* compactness (perimeter^2 / area - 1.0)\n",
    "* concavity (severity of concave portions of the contour)\n",
    "* concave points (number of concave portions of the contour)\n",
    "* symmetry\n",
    "* fractal dimension (“coastline approximation” - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 569 samples with 30 features each.\n",
      "The mean of each feature is: [1.41272917e+01 1.92896485e+01 9.19690334e+01 6.54889104e+02\n",
      " 9.63602812e-02 1.04340984e-01 8.87993158e-02 4.89191459e-02\n",
      " 1.81161863e-01 6.27976098e-02 4.05172056e-01 1.21685343e+00\n",
      " 2.86605923e+00 4.03370791e+01 7.04097891e-03 2.54781388e-02\n",
      " 3.18937163e-02 1.17961371e-02 2.05422988e-02 3.79490387e-03\n",
      " 1.62691898e+01 2.56772232e+01 1.07261213e+02 8.80583128e+02\n",
      " 1.32368594e-01 2.54265044e-01 2.72188483e-01 1.14606223e-01\n",
      " 2.90075571e-01 8.39458172e-02]\n",
      "The standar deviation of each feature is: [3.52095076e+00 4.29725464e+00 2.42776193e+01 3.51604754e+02\n",
      " 1.40517641e-02 5.27663291e-02 7.96497253e-02 3.87687325e-02\n",
      " 2.73901809e-02 7.05415588e-03 2.77068942e-01 5.51163427e-01\n",
      " 2.02007710e+00 4.54510134e+01 2.99987837e-03 1.78924359e-02\n",
      " 3.01595231e-02 6.16486075e-03 8.25910439e-03 2.64374475e-03\n",
      " 4.82899258e+00 6.14085432e+00 3.35730016e+01 5.68856459e+02\n",
      " 2.28123569e-02 1.57198171e-01 2.08440875e-01 6.56745545e-02\n",
      " 6.18130785e-02 1.80453893e-02]\n"
     ]
    }
   ],
   "source": [
    "# Load and shuffle the data\n",
    "(X, y) = load_breast_cancer(return_X_y=True)\n",
    "n_samples, n_features = X.shape\n",
    "print(\"There are {} samples with {} features each.\".format(n_samples, n_features))\n",
    "\n",
    "perm = np.random.permutation(n_samples)\n",
    "X, y = X[perm, :], y[perm]\n",
    "\n",
    "# Mean and standar deviation of each feature:\n",
    "print(\"The mean of each feature is: {}\".format(X.mean(axis=0)))\n",
    "print(\"The standar deviation of each feature is: {}\".format(X.std(axis=0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To achieve better performance, at least with our logistic regression baseline model, we may standarize the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = (X- X.mean(axis=0))/X.std(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross validation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate(model, k):\n",
    "    X_fold = X\n",
    "    y_fold = y\n",
    "    pivot = int(X_fold.shape[0]/k)\n",
    "    cum_acc = 0\n",
    "    for _ in tqdm(range(k)):\n",
    "        # Always take firt fold as test\n",
    "        x_test, y_test = X_fold[:pivot, :], y_fold[:pivot]\n",
    "        x_train, y_train = X_fold[pivot:, :], y_fold[pivot:]\n",
    "        \n",
    "        # fit the model\n",
    "        model.fit(X=x_train, y=y_train)\n",
    "        y_hat = model.predict(x_test)\n",
    "        \n",
    "        cum_acc += balanced_accuracy_score(y_test, y_hat)\n",
    "        \n",
    "        X_fold = np.concatenate((x_train, x_test))\n",
    "        y_fold = np.concatenate((y_train, y_test))\n",
    "        \n",
    "    return cum_acc/k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a logistic regression baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the test set: 0.9883040935672515\n",
      "Balanced Accuracy on the test set: 0.9841269841269842\n"
     ]
    }
   ],
   "source": [
    "# Initialize and fit the model.\n",
    "model = LogisticRegression(n_features=n_features)\n",
    "loss, acc = model.fit(X[:int(0.7*n_samples), :], y[:int(0.7*n_samples)], iterations=100, learning_rate=1e-4)\n",
    "\n",
    "# Visualize training.\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=[15, 5])\n",
    "\n",
    "ax1.plot(loss)\n",
    "ax1.set_title('Loss')\n",
    "\n",
    "ax2.plot(acc)\n",
    "ax2.set_title('Accuracy')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Evaluate on a held-out set\n",
    "y_pred = model.predict(X[int(0.7*n_samples):])\n",
    "acc = np.mean(np.round(y_pred)==y[int(0.7*n_samples):])\n",
    "print(\"Accuracy on the test set: {}\".format(acc))\n",
    "print(\"Balanced Accuracy on the test set: {}\".format(balanced_accuracy_score(y[int(0.7*n_samples):], np.round(y_pred))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The balanced-accuracy to beat is around 0.984, lets try with a single tree:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = DecisionTreeClassifier(max_depth=10, min_impurity=0.05)\n",
    "tree.fit(X[:int(0.7*n_samples), :], y[:int(0.7*n_samples)])\n",
    "\n",
    "# Evaluate on train and test set.\n",
    "y_pred = tree.predict(X[:int(0.7*n_samples), :])\n",
    "acc = np.mean(y_pred==y[:int(0.7*n_samples)])\n",
    "print(\"Accuracy on the train set: {}\".format(acc))\n",
    "\n",
    "y_pred = tree.predict(X[int(0.7*n_samples):, :])\n",
    "acc = np.mean(y_pred==y[int(0.7*n_samples):])\n",
    "print(\"Accuracy on the test set: {}\".format(acc))\n",
    "print(\"Balanced Accuracy on the test set: {}\".format(balanced_accuracy_score(y[int(0.7*n_samples):], np.round(y_pred))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A single tree is not capable of beating the logistic regression model. Will a combination of these?\n",
    "\n",
    "## Ensembling\n",
    "\n",
    "### Bagging\n",
    "Let's try first with a simple bag of trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model\n",
    "base_tree = DecisionTreeClassifier(max_depth=15, min_impurity=0.1)\n",
    "bag_trees = BaggingClassifier(base_tree, n_models=50)\n",
    "\n",
    "# Validate\n",
    "acc = cross_validate(bag_trees, 5)\n",
    "print(\"Cross-Validation accuracy: %.3f\" % acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model\n",
    "base_tree = DecisionTreeClassifier(max_depth=15, min_impurity=0.1, p=np.sqrt(n_features)/n_features)\n",
    "bag_trees = BaggingClassifier(base_tree, n_models=100)\n",
    "\n",
    "# Validate\n",
    "acc = cross_validate(bag_trees, 5)\n",
    "print(\"Cross-Validation accuracy: %.3f\" % acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                            | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting model nº1\n",
      "Current loss: 0.7977252887803212\n",
      "new loss: 0.18278157999222214\n",
      "Found Rho=28.586389967108317, after 10609 steps\n",
      "Fitting model nº2\n",
      "Current loss: 0.7246999285809234\n",
      "new loss: 0.1766791280866352\n",
      "Found Rho=24.03946286168805, after 6725 steps\n",
      "Fitting model nº3\n",
      "Current loss: 0.659248041713302\n",
      "new loss: 0.16317304097470672\n",
      "Found Rho=20.835171901235743, after 4689 steps\n",
      "Fitting model nº4\n",
      "Current loss: 0.5977834735788778\n",
      "new loss: 0.15577909232576326\n",
      "Found Rho=17.90241920803098, after 3226 steps\n",
      "Fitting model nº5\n",
      "Current loss: 0.5403300777298207\n",
      "new loss: 0.15197213060075784\n",
      "Found Rho=15.302710136042853, after 2222 steps\n",
      "Fitting model nº6\n",
      "Current loss: 0.4873453249728895\n",
      "new loss: 0.1502119715360159\n",
      "Found Rho=13.058265374757584, after 1550 steps\n",
      "Fitting model nº7\n",
      "Current loss: 0.43932978979931964\n",
      "new loss: 0.14956310277877966\n",
      "Found Rho=11.149384028438737, after 1103 steps\n",
      "Fitting model nº8\n",
      "Current loss: 0.396659947913778\n",
      "new loss: 0.1494743975809244\n",
      "Found Rho=9.570622613408478, after 806 steps\n",
      "Fitting model nº9\n",
      "Current loss: 0.35937015432295094\n",
      "new loss: 0.14963645229024225\n",
      "Found Rho=8.275381199587411, after 606 steps\n",
      "Fitting model nº10\n",
      "Current loss: 0.32725515173075576\n",
      "new loss: 0.14988814413342522\n",
      "Found Rho=7.237677099869449, after 470 steps\n",
      "Fitting model nº11\n",
      "Current loss: 0.2998446112375077\n",
      "new loss: 0.15015168612560104\n",
      "Found Rho=6.3781132755364425, after 374 steps\n",
      "Fitting model nº12\n",
      "Current loss: 0.2766878532923493\n",
      "new loss: 0.15039374735503597\n",
      "Found Rho=5.669144074723035, after 305 steps\n",
      "Fitting model nº13\n",
      "Current loss: 0.2572485403302221\n",
      "new loss: 0.15060428657769986\n",
      "Found Rho=5.09720608466285, after 255 steps\n",
      "Fitting model nº14\n",
      "Current loss: 0.24094131511821304\n",
      "new loss: 0.15078188246846994\n",
      "Found Rho=4.610924035572487, after 217 steps\n",
      "Fitting model nº15\n",
      "Current loss: 0.22730732295061648\n",
      "new loss: 0.1509303590057471\n",
      "Found Rho=4.205884951355587, after 188 steps\n",
      "Fitting model nº16\n",
      "Current loss: 0.2158950058930806\n",
      "new loss: 0.15105343573583732\n",
      "Found Rho=3.8550493424016454, after 165 steps\n",
      "Fitting model nº17\n",
      "Current loss: 0.2063451921475288\n",
      "new loss: 0.1511545141307387\n",
      "Found Rho=3.537734884487885, after 146 steps\n",
      "Fitting model nº18\n",
      "Current loss: 0.19837027226123582\n",
      "new loss: 0.15123923189847824\n",
      "Found Rho=3.2742084361684984, after 131 steps\n",
      "Fitting model nº19\n",
      "Current loss: 0.19166735373510949\n",
      "new loss: 0.15131125313239066\n",
      "Found Rho=3.054456096867671, after 119 steps\n",
      "Fitting model nº20\n",
      "Current loss: 0.18599655037791452\n",
      "new loss: 0.15136990964561636\n",
      "Found Rho=2.8351505233858196, after 108 steps\n",
      "Fitting model nº21\n",
      "Current loss: 0.18122464355058504\n",
      "new loss: 0.15142014839238027\n",
      "Found Rho=2.6497654211986656, after 99 steps\n",
      "Fitting model nº22\n",
      "Current loss: 0.17717993701957874\n",
      "new loss: 0.15146221362729426\n",
      "Found Rho=2.4765158478220273, after 91 steps\n",
      "Fitting model nº23\n",
      "Current loss: 0.1737490044526213\n",
      "new loss: 0.1514979044719844\n",
      "Found Rho=2.3191321242870213, after 84 steps\n",
      "Fitting model nº24\n",
      "Current loss: 0.17082957230797086\n",
      "new loss: 0.15152870110781733\n",
      "Found Rho=2.180690722442843, after 78 steps\n",
      "Fitting model nº25\n",
      "Current loss: 0.16833196086376448\n",
      "new loss: 0.15155637452725812\n",
      "Found Rho=2.0636956809625966, after 73 steps\n",
      "Fitting model nº26\n",
      "Current loss: 0.16617916396928273\n",
      "new loss: 0.15157871802552747\n",
      "Found Rho=1.9409099037297066, after 68 steps\n",
      "Fitting model nº27\n",
      "Current loss: 0.16433262531263426\n",
      "new loss: 0.15159649515391968\n",
      "Found Rho=1.813119249076178, after 63 steps\n",
      "Fitting model nº28\n",
      "Current loss: 0.16275622207566312\n",
      "new loss: 0.15161312569266738\n",
      "Found Rho=1.710636578442061, after 59 steps\n",
      "Fitting model nº29\n",
      "Current loss: 0.16139428317102936\n",
      "new loss: 0.15162984436928054\n",
      "Found Rho=1.6347350928790256, after 56 steps\n",
      "Fitting model nº30\n",
      "Current loss: 0.16020118690671362\n",
      "new loss: 0.15164030448498175\n",
      "Found Rho=1.5266511859543106, after 52 steps\n",
      "Fitting model nº31\n",
      "Current loss: 0.15917816667043425\n",
      "new loss: 0.1516514569864269\n",
      "Found Rho=1.4461420566323127, after 49 steps\n",
      "Fitting model nº32\n",
      "Current loss: 0.15828666216012802\n",
      "new loss: 0.15166058312937677\n",
      "Found Rho=1.3639058343643178, after 46 steps\n",
      "Fitting model nº33\n",
      "Current loss: 0.15751194731380566\n",
      "new loss: 0.1516715601736408\n",
      "Found Rho=1.3103562839440284, after 44 steps\n",
      "Fitting model nº34\n",
      "Current loss: 0.15682549188220835\n",
      "new loss: 0.15167671621226905\n",
      "Found Rho=1.225495550997237, after 41 steps\n",
      "Fitting model nº35\n",
      "Current loss: 0.15623262544903932\n",
      "new loss: 0.15168442240282665\n",
      "Found Rho=1.1698094264861856, after 39 steps\n",
      "Fitting model nº36\n",
      "Current loss: 0.15570921539065394\n",
      "new loss: 0.15169104051096688\n",
      "Found Rho=1.113333076002772, after 37 steps\n",
      "Fitting model nº37\n",
      "Current loss: 0.15524813189139963\n",
      "new loss: 0.1516963301486856\n",
      "Found Rho=1.0561516814470617, after 35 steps\n",
      "Fitting model nº38\n",
      "Current loss: 0.15484286653717985\n",
      "new loss: 0.15170026661384062\n",
      "Found Rho=0.9983425935168669, after 33 steps\n",
      "Fitting model nº39\n",
      "Current loss: 0.1544875000447231\n",
      "new loss: 0.15170302757878623\n",
      "Found Rho=0.9399760212949309, after 31 steps\n",
      "Fitting model nº40\n",
      "Current loss: 0.15417666787931272\n",
      "new loss: 0.15170498454340345\n",
      "Found Rho=0.8811157119627194, after 29 steps\n",
      "Fitting model nº41\n",
      "Current loss: 0.15390552512591682\n",
      "new loss: 0.15171072762910007\n",
      "Found Rho=0.8525059701907372, after 28 steps\n",
      "Fitting model nº42\n",
      "Current loss: 0.15366122258298104\n",
      "new loss: 0.15171080678711313\n",
      "Found Rho=0.7929197035762179, after 26 steps\n",
      "Fitting model nº43\n",
      "Current loss: 0.15344942780686516\n",
      "new loss: 0.151715033141378\n",
      "Found Rho=0.7637400838703458, after 25 steps\n",
      "Fitting model nº44\n",
      "Current loss: 0.15325907842200406\n",
      "new loss: 0.15171417068120469\n",
      "Found Rho=0.7035682001206021, after 23 steps\n",
      "Fitting model nº45\n",
      "Current loss: 0.1530952478620134\n",
      "new loss: 0.15171667940608524\n",
      "Found Rho=0.6739297265819516, after 22 steps\n",
      "Fitting model nº46\n",
      "Current loss: 0.15294840624962475\n",
      "new loss: 0.15171896060848766\n",
      "Found Rho=0.6441359642734906, after 21 steps\n",
      "Fitting model nº47\n",
      "Current loss: 0.15281704858736048\n",
      "new loss: 0.15172090466130414\n",
      "Found Rho=0.6142000384189493, after 20 steps\n",
      "Fitting model nº48\n",
      "Current loss: 0.15269978241175308\n",
      "new loss: 0.15172244490204462\n",
      "Found Rho=0.5841341671542141, after 19 steps\n",
      "Fitting model nº49\n",
      "Current loss: 0.15259532140441653\n",
      "new loss: 0.15172355640562663\n",
      "Found Rho=0.5539497373136322, after 18 steps\n",
      "Fitting model nº50\n",
      "Current loss: 0.15250247931296995\n",
      "new loss: 0.15172425511999835\n",
      "Found Rho=0.5236573762600968, after 17 steps\n",
      "Fitting model nº51\n",
      "Current loss: 0.15242016420070645\n",
      "new loss: 0.1517245973450891\n",
      "Found Rho=0.49326701985790217, after 16 steps\n",
      "Fitting model nº52\n",
      "Current loss: 0.152347373036728\n",
      "new loss: 0.15172467953940727\n",
      "Found Rho=0.462787976738013, after 15 steps\n",
      "Fitting model nº53\n",
      "Current loss: 0.1522831866325056\n",
      "new loss: 0.15172463844218717\n",
      "Found Rho=0.43222898904417, after 14 steps\n",
      "Fitting model nº54\n",
      "Current loss: 0.15222676492627266\n",
      "new loss: 0.1517285343518461\n",
      "Found Rho=0.43260407770508763, after 14 steps\n",
      "Fitting model nº55\n",
      "Current loss: 0.15217364556718305\n",
      "new loss: 0.15172758047606158\n",
      "Found Rho=0.4019423561505056, after 13 steps\n",
      "Fitting model nº56\n",
      "Current loss: 0.1521272462981428\n",
      "new loss: 0.15172671421281986\n",
      "Found Rho=0.3712178067603237, after 12 steps\n",
      "Fitting model nº57\n",
      "Current loss: 0.15208688241944623\n",
      "new loss: 0.1517301708510697\n",
      "Found Rho=0.37148255138245, after 12 steps\n",
      "Fitting model nº58\n",
      "Current loss: 0.1520488458120973\n",
      "new loss: 0.15172851624994527\n",
      "Found Rho=0.3406780321845702, after 11 steps\n",
      "Fitting model nº59\n",
      "Current loss: 0.15201600583159766\n",
      "new loss: 0.15172734460816645\n",
      "Found Rho=0.3098255709816689, after 10 steps\n",
      "Fitting model nº60\n",
      "Current loss: 0.1519878137700752\n",
      "new loss: 0.1517295668360776\n",
      "Found Rho=0.31000354298264565, after 10 steps\n",
      "Fitting model nº61\n",
      "Current loss: 0.15196118077290355\n",
      "new loss: 0.15172801393525293\n",
      "Found Rho=0.27909072328464574, after 9 steps\n",
      "Fitting model nº62\n",
      "Current loss: 0.15193853562023216\n",
      "new loss: 0.1517299892199895\n",
      "Found Rho=0.27923210379477975, after 9 steps\n",
      "Fitting model nº63\n",
      "Current loss: 0.1519171272268845\n",
      "new loss: 0.15173295714112733\n",
      "Found Rho=0.27937185380959184, after 9 steps\n",
      "Fitting model nº64\n",
      "Current loss: 0.15189694362277673\n",
      "new loss: 0.15173008609501465\n",
      "Found Rho=0.24839162595866598, after 8 steps\n",
      "Fitting model nº65\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current loss: 0.15188002521453114\n",
      "new loss: 0.15173250341013353\n",
      "Found Rho=0.2485001933625329, after 8 steps\n",
      "Fitting model nº66\n",
      "Current loss: 0.1518640563874951\n",
      "new loss: 0.15172971278957204\n",
      "Found Rho=0.21747784312632815, after 7 steps\n",
      "Fitting model nº67\n",
      "Current loss: 0.15185085927840264\n",
      "new loss: 0.15173146051286618\n",
      "Found Rho=0.21755978421166983, after 7 steps\n",
      "Fitting model nº68\n",
      "Current loss: 0.1518383770319821\n",
      "new loss: 0.15173380639217102\n",
      "Found Rho=0.21764098326914966, after 7 steps\n",
      "Fitting model nº69\n",
      "Current loss: 0.15182660416800364\n",
      "new loss: 0.15173040160939988\n",
      "Found Rho=0.1865726520510521, after 6 steps\n",
      "Fitting model nº70\n",
      "Current loss: 0.15181707595136243\n",
      "Converged, loss improvement: 9.528216641213616e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|████████████████▌                                                                  | 1/5 [02:24<09:38, 144.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting model nº1\n",
      "Current loss: 0.7991711950943517\n",
      "new loss: 0.20182360802936172\n",
      "Found Rho=27.114172313084513, after 8640 steps\n",
      "Fitting model nº2\n",
      "Current loss: 0.7250249159840251\n",
      "new loss: 0.1457199355146264\n",
      "Found Rho=24.31102608114704, after 5909 steps\n",
      "Fitting model nº3\n",
      "Current loss: 0.6517798776173392\n",
      "new loss: 0.15139936275034965\n",
      "Found Rho=19.560297202109208, after 3819 steps\n",
      "Fitting model nº4\n",
      "Current loss: 0.5884606504165036\n",
      "new loss: 0.14450105288787626\n",
      "Found Rho=16.9317836278203, after 2655 steps\n",
      "Fitting model nº5\n",
      "Current loss: 0.52931580750041\n",
      "new loss: 0.14108851049249102\n",
      "Found Rho=14.597960747260245, after 1851 steps\n",
      "Fitting model nº6\n",
      "Current loss: 0.47480885512138826\n",
      "new loss: 0.14091886155664934\n",
      "Found Rho=12.448448267397673, after 1297 steps\n",
      "Fitting model nº7\n",
      "Current loss: 0.42601304761828723\n",
      "new loss: 0.14041800046904987\n",
      "Found Rho=10.738316195967007, after 937 steps\n",
      "Fitting model nº8\n",
      "Current loss: 0.3826995764835836\n",
      "new loss: 0.14046429537690094\n",
      "Found Rho=9.310759220019278, after 695 steps\n",
      "Fitting model nº9\n",
      "Current loss: 0.34494433322806767\n",
      "new loss: 0.1407422112161906\n",
      "Found Rho=8.106178041647993, after 529 steps\n",
      "Fitting model nº10\n",
      "Current loss: 0.31264526936526615\n",
      "new loss: 0.13812267705664186\n",
      "Found Rho=7.237506765528414, after 420 steps\n",
      "Fitting model nº11\n",
      "Current loss: 0.2846781316722811\n",
      "new loss: 0.14060757950772915\n",
      "Found Rho=6.328948358757225, after 334 steps\n",
      "Fitting model nº12\n",
      "Current loss: 0.2617360644812445\n",
      "new loss: 0.1408914801752176\n",
      "Found Rho=5.666147536050356, after 276 steps\n",
      "Fitting model nº13\n",
      "Current loss: 0.24261518196586687\n",
      "new loss: 0.13834463706345884\n",
      "Found Rho=5.193985520722479, after 236 steps\n",
      "Fitting model nº14\n",
      "Current loss: 0.2262584265680572\n",
      "new loss: 0.14066890380041777\n",
      "Found Rho=4.6440800178078545, after 200 steps\n",
      "Fitting model nº15\n",
      "Current loss: 0.2130808894257069\n",
      "new loss: 0.13843181591358222\n",
      "Found Rho=4.340247286876676, after 178 steps\n",
      "Fitting model nº16\n",
      "Current loss: 0.20170871946358032\n",
      "new loss: 0.14039430100815484\n",
      "Found Rho=3.919829705418031, after 155 steps\n",
      "Fitting model nº17\n",
      "Current loss: 0.19257526409764372\n",
      "new loss: 0.1384223685095714\n",
      "Found Rho=3.6913727165387717, after 141 steps\n",
      "Fitting model nº18\n",
      "Current loss: 0.1846423556905947\n",
      "new loss: 0.13851189222219737\n",
      "Found Rho=3.4164950553031233, after 127 steps\n",
      "Fitting model nº19\n",
      "Current loss: 0.17802035854293097\n",
      "new loss: 0.13978565846089788\n",
      "Found Rho=3.103130527216544, after 113 steps\n",
      "Fitting model nº20\n",
      "Current loss: 0.17269413612157547\n",
      "new loss: 0.1384430738921137\n",
      "Found Rho=2.9740757454209636, after 106 steps\n",
      "Fitting model nº21\n",
      "Current loss: 0.167964967177887\n",
      "new loss: 0.13849042493285674\n",
      "Found Rho=2.7665862136426034, after 97 steps\n",
      "Fitting model nº22\n",
      "Current loss: 0.16398507146344196\n",
      "new loss: 0.1393147711808917\n",
      "Found Rho=2.540674461505885, after 88 steps\n",
      "Fitting model nº23\n",
      "Current loss: 0.16073912110651478\n",
      "new loss: 0.13841611238281137\n",
      "Found Rho=2.459877732373364, after 84 steps\n",
      "Fitting model nº24\n",
      "Current loss: 0.15780654886481782\n",
      "new loss: 0.13844529538502062\n",
      "Found Rho=2.308475915968952, after 78 steps\n",
      "Fitting model nº25\n",
      "Current loss: 0.15530389059228186\n",
      "new loss: 0.13846757156913697\n",
      "Found Rho=2.1501422985559486, after 72 steps\n",
      "Fitting model nº26\n",
      "Current loss: 0.15317880454310553\n",
      "new loss: 0.13882312255849544\n",
      "Found Rho=2.014214317346493, after 67 steps\n",
      "Fitting model nº27\n",
      "Current loss: 0.15139185621538578\n",
      "new loss: 0.13839911928777698\n",
      "Found Rho=1.909818723814359, after 63 steps\n",
      "Fitting model nº28\n",
      "Current loss: 0.1498019744955887\n",
      "new loss: 0.1384151887553947\n",
      "Found Rho=1.7995839524029735, after 59 steps\n",
      "Fitting model nº29\n",
      "Current loss: 0.1484271322879261\n",
      "new loss: 0.13843157848307006\n",
      "Found Rho=1.717712554017576, after 56 steps\n",
      "Fitting model nº30\n",
      "Current loss: 0.14722117886869307\n",
      "new loss: 0.13844154410453216\n",
      "Found Rho=1.6025544343760039, after 52 steps\n",
      "Fitting model nº31\n",
      "Current loss: 0.14618540064065363\n",
      "new loss: 0.13845043027172538\n",
      "Found Rho=1.5151912803250962, after 49 steps\n",
      "Fitting model nº32\n",
      "Current loss: 0.14528787917497019\n",
      "new loss: 0.1383929021555675\n",
      "Found Rho=1.4608026825436384, after 47 steps\n",
      "Fitting model nº33\n",
      "Current loss: 0.14447845246651397\n",
      "new loss: 0.13840009944887435\n",
      "Found Rho=1.372286576667081, after 44 steps\n",
      "Fitting model nº34\n",
      "Current loss: 0.14377553162059822\n",
      "new loss: 0.1384056841563341\n",
      "Found Rho=1.2825949118362483, after 41 steps\n",
      "Fitting model nº35\n",
      "Current loss: 0.14316691538454812\n",
      "new loss: 0.13841356966413776\n",
      "Found Rho=1.223570391145346, after 39 steps\n",
      "Fitting model nº36\n",
      "Current loss: 0.14262825820013061\n",
      "new loss: 0.1384204680049115\n",
      "Found Rho=1.163864691872992, after 37 steps\n",
      "Fitting model nº37\n",
      "Current loss: 0.14215254575735753\n",
      "new loss: 0.1382426845102451\n",
      "Found Rho=1.134542972255547, after 36 steps\n",
      "Fitting model nº38\n",
      "Current loss: 0.14171405757613256\n",
      "new loss: 0.13838127472430164\n",
      "Found Rho=1.0428147151664173, after 33 steps\n",
      "Fitting model nº39\n",
      "Current loss: 0.14134376808274646\n",
      "new loss: 0.13838455923410886\n",
      "Found Rho=0.9814688112056272, after 31 steps\n",
      "Fitting model nº40\n",
      "Current loss: 0.14101902406482195\n",
      "new loss: 0.13838706463998815\n",
      "Found Rho=0.9196966013820315, after 29 steps\n",
      "Fitting model nº41\n",
      "Current loss: 0.1407350174837399\n",
      "new loss: 0.13839291480115584\n",
      "Found Rho=0.8895268821498267, after 28 steps\n",
      "Fitting model nº42\n",
      "Current loss: 0.14047849401262438\n",
      "new loss: 0.13839351191400642\n",
      "Found Rho=0.8271271347158385, after 26 steps\n",
      "Fitting model nº43\n",
      "Current loss: 0.14025556085537877\n",
      "new loss: 0.13817209916736184\n",
      "Found Rho=0.8601034920505749, after 27 steps\n",
      "Fitting model nº44\n",
      "Current loss: 0.14002731191569331\n",
      "new loss: 0.13836885936715504\n",
      "Found Rho=0.7657517683897493, after 24 steps\n",
      "Fitting model nº45\n",
      "Current loss: 0.13984642399329453\n",
      "new loss: 0.13836711275025032\n",
      "Found Rho=0.7026465566348051, after 22 steps\n",
      "Fitting model nº46\n",
      "Current loss: 0.13969096826180366\n",
      "new loss: 0.13836964133220195\n",
      "Found Rho=0.6714416564345772, after 21 steps\n",
      "Fitting model nº47\n",
      "Current loss: 0.1395516243357348\n",
      "new loss: 0.13837183770311823\n",
      "Found Rho=0.6401134767195236, after 20 steps\n",
      "Fitting model nº48\n",
      "Current loss: 0.13942698653803068\n",
      "new loss: 0.13837361990531155\n",
      "Found Rho=0.6086723834909412, after 19 steps\n",
      "Fitting model nº49\n",
      "Current loss: 0.13931575118357692\n",
      "new loss: 0.1383749525551499\n",
      "Found Rho=0.5771280605620153, after 18 steps\n",
      "Fitting model nº50\n",
      "Current loss: 0.1392167111870973\n",
      "new loss: 0.13815676770629007\n",
      "Found Rho=0.6096981721186409, after 19 steps\n",
      "Fitting model nº51\n",
      "Current loss: 0.13910700340100385\n",
      "new loss: 0.13835455348681502\n",
      "Found Rho=0.5138322233269896, after 16 steps\n",
      "Fitting model nº52\n",
      "Current loss: 0.139029102442264\n",
      "new loss: 0.1383547975469745\n",
      "Found Rho=0.48202544939127745, after 15 steps\n",
      "Fitting model nº53\n",
      "Current loss: 0.13896030504924287\n",
      "new loss: 0.1383549034088174\n",
      "Found Rho=0.45014869342808916, after 14 steps\n",
      "Fitting model nº54\n",
      "Current loss: 0.13889974305464747\n",
      "new loss: 0.13835904706346366\n",
      "Found Rho=0.4504798573477715, after 14 steps\n",
      "Fitting model nº55\n",
      "Current loss: 0.1388426486895884\n",
      "new loss: 0.13835815850114278\n",
      "Found Rho=0.4185131394120139, after 13 steps\n",
      "Fitting model nº56\n",
      "Current loss: 0.1387927098760619\n",
      "new loss: 0.1383573555271383\n",
      "Found Rho=0.3864911614402555, after 12 steps\n",
      "Fitting model nº57\n",
      "Current loss: 0.1387492123080529\n",
      "new loss: 0.13817384928266266\n",
      "Found Rho=0.4512422692479739, after 14 steps\n",
      "Fitting model nº58\n",
      "Current loss: 0.13869139835338423\n",
      "new loss: 0.13834434657449662\n",
      "Found Rho=0.3546740337736744, after 11 steps\n",
      "Fitting model nº59\n",
      "Current loss: 0.13865601881209486\n",
      "new loss: 0.1383431400438887\n",
      "Found Rho=0.32253536837088737, after 10 steps\n",
      "Fitting model nº60\n",
      "Current loss: 0.1386256180507358\n",
      "new loss: 0.13834560507195712\n",
      "Found Rho=0.32269311219071134, after 10 steps\n",
      "Fitting model nº61\n",
      "Current loss: 0.13859687431904888\n",
      "new loss: 0.13834396010726704\n",
      "Found Rho=0.2905012118423751, after 9 steps\n",
      "Fitting model nº62\n",
      "Current loss: 0.13857241424107192\n",
      "new loss: 0.13834616196978655\n",
      "Found Rho=0.2906267437164978, after 9 steps\n",
      "Fitting model nº63\n",
      "Current loss: 0.13854927317715346\n",
      "new loss: 0.1383494631028984\n",
      "Found Rho=0.2907509574286825, after 9 steps\n",
      "Fitting model nº64\n",
      "Current loss: 0.1385274404587709\n",
      "new loss: 0.1383463474096588\n",
      "Found Rho=0.2584994410088501, after 8 steps\n",
      "Fitting model nº65\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current loss: 0.13850912699063733\n",
      "new loss: 0.13820535917293347\n",
      "Found Rho=0.35570907597021606, after 11 steps\n",
      "Fitting model nº66\n",
      "Current loss: 0.138476718777825\n",
      "new loss: 0.13833502933629424\n",
      "Found Rho=0.22634133996369835, after 7 steps\n",
      "Fitting model nº67\n",
      "Current loss: 0.13846261391302958\n",
      "new loss: 0.13833715987418593\n",
      "Found Rho=0.22641411644195397, after 7 steps\n",
      "Fitting model nº68\n",
      "Current loss: 0.1384492759663972\n",
      "new loss: 0.13833431302024427\n",
      "Found Rho=0.19408996830390784, after 6 steps\n",
      "Fitting model nº69\n",
      "Current loss: 0.1384384523860199\n",
      "new loss: 0.13833562946730257\n",
      "Found Rho=0.19414287427293297, after 6 steps\n",
      "Fitting model nº70\n",
      "Current loss: 0.13842818537971172\n",
      "new loss: 0.13833743476853877\n",
      "Found Rho=0.1941954063671324, after 6 steps\n",
      "Fitting model nº71\n",
      "Current loss: 0.13841847188252124\n",
      "Converged, loss improvement: 9.71349719047776e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|█████████████████████████████████▏                                                 | 2/5 [04:58<07:21, 147.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting model nº1\n",
      "Current loss: 0.7963749091613539\n",
      "new loss: 0.20520648725000962\n",
      "Found Rho=31.263361909645624, after 12345 steps\n",
      "Fitting model nº2\n",
      "Current loss: 0.7244205557739939\n",
      "new loss: 0.18300048149582737\n",
      "Found Rho=27.329516067571642, after 8681 steps\n",
      "Fitting model nº3\n",
      "Current loss: 0.6577883306953081\n",
      "new loss: 0.1848661713573639\n",
      "Found Rho=21.709742973433364, after 5515 steps\n",
      "Fitting model nº4\n",
      "Current loss: 0.5998364105287508\n",
      "new loss: 0.17654765178179294\n",
      "Found Rho=18.714311751113776, after 3779 steps\n",
      "Fitting model nº5\n",
      "Current loss: 0.5451209585383987\n",
      "new loss: 0.1719765922145873\n",
      "Found Rho=16.05993086092111, after 2591 steps\n",
      "Fitting model nº6\n",
      "Current loss: 0.4941536227640905\n",
      "new loss: 0.16963337368361542\n",
      "Found Rho=13.752079437967922, after 1797 steps\n",
      "Fitting model nº7\n",
      "Current loss: 0.44755202813788925\n",
      "new loss: 0.1685733077249213\n",
      "Found Rho=11.805338594802857, after 1273 steps\n",
      "Fitting model nº8\n",
      "Current loss: 0.4057360246715878\n",
      "new loss: 0.16821115900925185\n",
      "Found Rho=10.173802590069837, after 925 steps\n",
      "Fitting model nº9\n",
      "Current loss: 0.3689506640494399\n",
      "new loss: 0.16819651701727673\n",
      "Found Rho=8.829897379030779, after 692 steps\n",
      "Fitting model nº10\n",
      "Current loss: 0.33714178854120624\n",
      "new loss: 0.16832793787328146\n",
      "Found Rho=7.723340462103428, after 533 steps\n",
      "Fitting model nº11\n",
      "Current loss: 0.31004947796741433\n",
      "new loss: 0.16849785198673112\n",
      "Found Rho=6.808140317643051, after 422 steps\n",
      "Fitting model nº12\n",
      "Current loss: 0.28726215075408296\n",
      "new loss: 0.16865538099072253\n",
      "Found Rho=6.073543258734881, after 344 steps\n",
      "Fitting model nº13\n",
      "Current loss: 0.26819693023687\n",
      "new loss: 0.1687807575958212\n",
      "Found Rho=5.463132242979773, after 287 steps\n",
      "Fitting model nº14\n",
      "Current loss: 0.25233381531305193\n",
      "new loss: 0.16886980984302308\n",
      "Found Rho=4.943884879391926, after 244 steps\n",
      "Fitting model nº15\n",
      "Current loss: 0.2391924076249445\n",
      "new loss: 0.16892732688866735\n",
      "Found Rho=4.5252394676378085, after 212 steps\n",
      "Fitting model nº16\n",
      "Current loss: 0.22826569048535691\n",
      "new loss: 0.1689573756321115\n",
      "Found Rho=4.145339423013018, after 186 steps\n",
      "Fitting model nº17\n",
      "Current loss: 0.21921895995531349\n",
      "new loss: 0.1689687244701578\n",
      "Found Rho=3.835784288773936, after 166 steps\n",
      "Fitting model nº18\n",
      "Current loss: 0.21167675793085075\n",
      "new loss: 0.16896437958503122\n",
      "Found Rho=3.5481967937831933, after 149 steps\n",
      "Fitting model nº19\n",
      "Current loss: 0.20540008317631805\n",
      "new loss: 0.16895047961935147\n",
      "Found Rho=3.297101164196988, after 135 steps\n",
      "Fitting model nº20\n",
      "Current loss: 0.20015332150639087\n",
      "new loss: 0.16892996959517698\n",
      "Found Rho=3.068564920567237, after 123 steps\n",
      "Fitting model nº21\n",
      "Current loss: 0.19575676450510165\n",
      "new loss: 0.16890635190460912\n",
      "Found Rho=2.8704999632263175, after 113 steps\n",
      "Fitting model nº22\n",
      "Current loss: 0.19204836067930225\n",
      "new loss: 0.16888037856244645\n",
      "Found Rho=2.6826703772440283, after 104 steps\n",
      "Fitting model nº23\n",
      "Current loss: 0.18891720731184092\n",
      "new loss: 0.16885584934101072\n",
      "Found Rho=2.5357524539240623, after 97 steps\n",
      "Fitting model nº24\n",
      "Current loss: 0.18623821457353634\n",
      "new loss: 0.16882968329527906\n",
      "Found Rho=2.3796726040286766, after 90 steps\n",
      "Fitting model nº25\n",
      "Current loss: 0.18395777596063323\n",
      "new loss: 0.16880530129725335\n",
      "Found Rho=2.2431221791245157, after 84 steps\n",
      "Fitting model nº26\n",
      "Current loss: 0.18200327145888695\n",
      "new loss: 0.16878061390305987\n",
      "Found Rho=2.1006090719337243, after 78 steps\n",
      "Fitting model nº27\n",
      "Current loss: 0.18033460488924796\n",
      "new loss: 0.1687587632121571\n",
      "Found Rho=1.9806878718574636, after 73 steps\n",
      "Fitting model nº28\n",
      "Current loss: 0.1788963220393575\n",
      "new loss: 0.168740113539263\n",
      "Found Rho=1.884749257165526, after 69 steps\n",
      "Fitting model nº29\n",
      "Current loss: 0.1776427663871224\n",
      "new loss: 0.16871936746862073\n",
      "Found Rho=1.7580441666926419, after 64 steps\n",
      "Fitting model nº30\n",
      "Current loss: 0.1765691251148944\n",
      "new loss: 0.16870460606921436\n",
      "Found Rho=1.6845624144854037, after 61 steps\n",
      "Fitting model nº31\n",
      "Current loss: 0.17562256050055305\n",
      "new loss: 0.16868762320773423\n",
      "Found Rho=1.5811990760826113, after 57 steps\n",
      "Fitting model nº32\n",
      "Current loss: 0.1748035811631871\n",
      "new loss: 0.16867445077980864\n",
      "Found Rho=1.5042101357801512, after 54 steps\n",
      "Fitting model nº33\n",
      "Current loss: 0.17408399660590423\n",
      "new loss: 0.16866191572528386\n",
      "Found Rho=1.4259006810411925, after 51 steps\n",
      "Fitting model nº34\n",
      "Current loss: 0.1734530096607764\n",
      "new loss: 0.16864983294351404\n",
      "Found Rho=1.3464317188357997, after 48 steps\n",
      "Fitting model nº35\n",
      "Current loss: 0.17290088828699196\n",
      "new loss: 0.1686383852487838\n",
      "Found Rho=1.2659465703698363, after 45 steps\n",
      "Fitting model nº36\n",
      "Current loss: 0.17241889139552027\n",
      "new loss: 0.16863060318610357\n",
      "Found Rho=1.2130546728601705, after 43 steps\n",
      "Fitting model nº37\n",
      "Current loss: 0.17198948831574723\n",
      "new loss: 0.1686201022388854\n",
      "Found Rho=1.1310278515033994, after 40 steps\n",
      "Fitting model nº38\n",
      "Current loss: 0.17161665839061593\n",
      "new loss: 0.16861293318698195\n",
      "Found Rho=1.076879968864657, after 38 steps\n",
      "Fitting model nº39\n",
      "Current loss: 0.1712855267229083\n",
      "new loss: 0.16860622321264074\n",
      "Found Rho=1.0222674427809448, after 36 steps\n",
      "Fitting model nº40\n",
      "Current loss: 0.17099200187445418\n",
      "new loss: 0.1685998778230822\n",
      "Found Rho=0.9672389934623822, after 34 steps\n",
      "Fitting model nº41\n",
      "Current loss: 0.17073235864521372\n",
      "new loss: 0.16859394158456154\n",
      "Found Rho=0.9118388597681186, after 32 steps\n",
      "Fitting model nº42\n",
      "Current loss: 0.17050321117084238\n",
      "new loss: 0.16859106282748726\n",
      "Found Rho=0.884834416943632, after 31 steps\n",
      "Fitting model nº43\n",
      "Current loss: 0.1702949523123718\n",
      "new loss: 0.16858523901271208\n",
      "Found Rho=0.8288807154534799, after 29 steps\n",
      "Fitting model nº44\n",
      "Current loss: 0.17011211830555714\n",
      "new loss: 0.16858315404312715\n",
      "Found Rho=0.8014395154057865, after 28 steps\n",
      "Fitting model nº45\n",
      "Current loss: 0.16994633449623464\n",
      "new loss: 0.16857747126817185\n",
      "Found Rho=0.7450305142258298, after 26 steps\n",
      "Fitting model nº46\n",
      "Current loss: 0.16980167661071577\n",
      "new loss: 0.16857541595025058\n",
      "Found Rho=0.7172306055290985, after 25 steps\n",
      "Fitting model nº47\n",
      "Current loss: 0.16967083827483465\n",
      "new loss: 0.16857376973554725\n",
      "Found Rho=0.6893073482529191, after 24 steps\n",
      "Fitting model nº48\n",
      "Current loss: 0.1695527122843046\n",
      "new loss: 0.16856828130507898\n",
      "Found Rho=0.6323902629850324, after 22 steps\n",
      "Fitting model nº49\n",
      "Current loss: 0.16945076835238204\n",
      "new loss: 0.16856628836720616\n",
      "Found Rho=0.6041965541482779, after 21 steps\n",
      "Fitting model nº50\n",
      "Current loss: 0.1693590119534696\n",
      "new loss: 0.1685644001552784\n",
      "Found Rho=0.5759115010130484, after 20 steps\n",
      "Fitting model nº51\n",
      "Current loss: 0.1692765920895276\n",
      "new loss: 0.16856256080641904\n",
      "Found Rho=0.5475424556139179, after 19 steps\n",
      "Fitting model nº52\n",
      "Current loss: 0.16920271729951927\n",
      "new loss: 0.1685607447760317\n",
      "Found Rho=0.5190963261941585, after 18 steps\n",
      "Fitting model nº53\n",
      "Current loss: 0.16913665256565505\n",
      "new loss: 0.16855895657081998\n",
      "Found Rho=0.49057961758019636, after 17 steps\n",
      "Fitting model nº54\n",
      "Current loss: 0.16907771645238504\n",
      "new loss: 0.16855723061133362\n",
      "Found Rho=0.46199846881241424, after 16 steps\n",
      "Fitting model nº55\n",
      "Current loss: 0.169025278466767\n",
      "new loss: 0.1685589578857603\n",
      "Found Rho=0.4623404242349368, after 16 steps\n",
      "Fitting model nº56\n",
      "Current loss: 0.16897574049944664\n",
      "new loss: 0.1685568843764629\n",
      "Found Rho=0.43367564326843, after 15 steps\n",
      "Fitting model nº57\n",
      "Current loss: 0.16893190738216035\n",
      "new loss: 0.16855487894551177\n",
      "Found Rho=0.4049585604127254, after 14 steps\n",
      "Fitting model nº58\n",
      "Current loss: 0.1688932495024005\n",
      "new loss: 0.1685530650354787\n",
      "Found Rho=0.37619433852831907, after 13 steps\n",
      "Fitting model nº59\n",
      "Current loss: 0.16885928098857916\n",
      "new loss: 0.16855464327665703\n",
      "Found Rho=0.3764100192860325, after 13 steps\n",
      "Fitting model nº60\n",
      "Current loss: 0.16882714848504757\n",
      "new loss: 0.16855242116102562\n",
      "Found Rho=0.34758534348888837, after 12 steps\n",
      "Fitting model nº61\n",
      "Current loss: 0.1687991050026954\n",
      "new loss: 0.1685506021926808\n",
      "Found Rho=0.3187236484540033, after 11 steps\n",
      "Fitting model nº62\n",
      "Current loss: 0.16877475052511096\n",
      "new loss: 0.16855174837365608\n",
      "Found Rho=0.31887387020896546, after 11 steps\n",
      "Fitting model nº63\n",
      "Current loss: 0.16875167690334072\n",
      "new loss: 0.16854970042821538\n",
      "Found Rho=0.2899651233894981, after 10 steps\n",
      "Fitting model nº64\n",
      "Current loss: 0.1687318054236051\n",
      "new loss: 0.16855092047555156\n",
      "Found Rho=0.29008722638842194, after 10 steps\n",
      "Fitting model nº65\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current loss: 0.16871297667101864\n",
      "new loss: 0.1685487635763133\n",
      "Found Rho=0.2611377783088182, after 9 steps\n",
      "Fitting model nº66\n",
      "Current loss: 0.16869691727314579\n",
      "new loss: 0.1685498560304555\n",
      "Found Rho=0.26123524461077385, after 9 steps\n",
      "Fitting model nº67\n",
      "Current loss: 0.16868169103568717\n",
      "new loss: 0.16854776735054774\n",
      "Found Rho=0.23225106398113893, after 8 steps\n",
      "Fitting model nº68\n",
      "Current loss: 0.16866885249260682\n",
      "new loss: 0.16854858627182392\n",
      "Found Rho=0.2323271065576668, after 8 steps\n",
      "Fitting model nº69\n",
      "Current loss: 0.16865666424764286\n",
      "new loss: 0.16854997975890215\n",
      "Found Rho=0.23240256143303967, after 8 steps\n",
      "Fitting model nº70\n",
      "Current loss: 0.16864512266033646\n",
      "new loss: 0.16854735704358723\n",
      "Found Rho=0.20337964848814896, after 7 steps\n",
      "Fitting model nº71\n",
      "Current loss: 0.1686355517694502\n",
      "Converged, loss improvement: 9.570890886267946e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|█████████████████████████████████████████████████▊                                 | 3/5 [07:36<05:01, 150.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting model nº1\n",
      "Current loss: 0.7982942103157974\n",
      "new loss: 0.19140721184674508\n",
      "Found Rho=30.357925843443496, after 10290 steps\n",
      "Fitting model nº2\n",
      "Current loss: 0.7198730611272625\n",
      "new loss: 0.20058971738993187\n",
      "Found Rho=22.11428966989522, after 6167 steps\n",
      "Fitting model nº3\n",
      "Current loss: 0.6594471769779567\n",
      "new loss: 0.18102284443662858\n",
      "Found Rho=20.713739234943162, after 4505 steps\n",
      "Fitting model nº4\n",
      "Current loss: 0.598576968743005\n",
      "new loss: 0.1802957574457948\n",
      "Found Rho=17.54268020567463, after 3015 steps\n",
      "Fitting model nº5\n",
      "Current loss: 0.5425898695019432\n",
      "new loss: 0.17240342824479876\n",
      "Found Rho=15.812952511690352, after 2126 steps\n",
      "Fitting model nº6\n",
      "Current loss: 0.488065816132749\n",
      "new loss: 0.17192368258442564\n",
      "Found Rho=12.682206361288785, after 1460 steps\n",
      "Fitting model nº7\n",
      "Current loss: 0.4423739314136873\n",
      "new loss: 0.16896890757482588\n",
      "Found Rho=11.110595279863501, after 1061 steps\n",
      "Fitting model nº8\n",
      "Current loss: 0.40088642845111766\n",
      "new loss: 0.1670484156213045\n",
      "Found Rho=9.777393945190717, after 790 steps\n",
      "Fitting model nº9\n",
      "Current loss: 0.3639407270382181\n",
      "new loss: 0.16579706926153198\n",
      "Found Rho=8.65256628695089, after 604 steps\n",
      "Fitting model nº10\n",
      "Current loss: 0.33166732921322817\n",
      "new loss: 0.16498112228358194\n",
      "Found Rho=7.697890608791128, after 474 steps\n",
      "Fitting model nº11\n",
      "Current loss: 0.3039982285745575\n",
      "new loss: 0.16445152864875917\n",
      "Found Rho=6.897100765390989, after 382 steps\n",
      "Fitting model nº12\n",
      "Current loss: 0.2806226007979231\n",
      "new loss: 0.1641110413506982\n",
      "Found Rho=6.211620561154781, after 315 steps\n",
      "Fitting model nº13\n",
      "Current loss: 0.2611313113535043\n",
      "new loss: 0.16227625355096686\n",
      "Found Rho=5.927689477090247, after 278 steps\n",
      "Fitting model nº14\n",
      "Current loss: 0.24414554964946153\n",
      "new loss: 0.1621255790407729\n",
      "Found Rho=5.402711839498387, after 238 steps\n",
      "Fitting model nº15\n",
      "Current loss: 0.2302317134647577\n",
      "new loss: 0.16203908692497848\n",
      "Found Rho=4.943857396055472, after 207 steps\n",
      "Fitting model nº16\n",
      "Current loss: 0.21887839935863931\n",
      "new loss: 0.16199499367595868\n",
      "Found Rho=4.528832107909323, after 182 steps\n",
      "Fitting model nº17\n",
      "Current loss: 0.2096436181108275\n",
      "new loss: 0.16198056386515752\n",
      "Found Rho=4.19425845635077, after 163 steps\n",
      "Fitting model nº18\n",
      "Current loss: 0.20206432023204235\n",
      "new loss: 0.16198248495768577\n",
      "Found Rho=3.860060507374719, after 146 steps\n",
      "Fitting model nº19\n",
      "Current loss: 0.19588101304449082\n",
      "new loss: 0.16199709853945451\n",
      "Found Rho=3.5960029019918553, after 133 steps\n",
      "Fitting model nº20\n",
      "Current loss: 0.19076739466868003\n",
      "new loss: 0.1620169984919375\n",
      "Found Rho=3.3321399611364524, after 121 steps\n",
      "Fitting model nº21\n",
      "Current loss: 0.18655115825110438\n",
      "new loss: 0.16204203882209184\n",
      "Found Rho=3.132453144633343, after 112 steps\n",
      "Fitting model nº22\n",
      "Current loss: 0.18301563993179978\n",
      "new loss: 0.16206624970127012\n",
      "Found Rho=2.9179577289611465, after 103 steps\n",
      "Fitting model nº23\n",
      "Current loss: 0.18006974887415514\n",
      "new loss: 0.16209014785977405\n",
      "Found Rho=2.720466945826005, after 95 steps\n",
      "Fitting model nº24\n",
      "Current loss: 0.17760452060597162\n",
      "new loss: 0.16211498616318676\n",
      "Found Rho=2.572561960600453, after 89 steps\n",
      "Fitting model nº25\n",
      "Current loss: 0.1755062299228391\n",
      "new loss: 0.16213510007285897\n",
      "Found Rho=2.388624908253225, after 82 steps\n",
      "Fitting model nº26\n",
      "Current loss: 0.17374710621943784\n",
      "new loss: 0.16215562969175204\n",
      "Found Rho=2.2583428712151874, after 77 steps\n",
      "Fitting model nº27\n",
      "Current loss: 0.17224075880398876\n",
      "new loss: 0.1621736310357537\n",
      "Found Rho=2.124108772929267, after 72 steps\n",
      "Fitting model nº28\n",
      "Current loss: 0.1709543970761811\n",
      "new loss: 0.1621890508376136\n",
      "Found Rho=1.9865375291352179, after 67 steps\n",
      "Fitting model nº29\n",
      "Current loss: 0.16985893119068304\n",
      "new loss: 0.16220354052591626\n",
      "Found Rho=1.8762857234423076, after 63 steps\n",
      "Fitting model nº30\n",
      "Current loss: 0.1689143062794547\n",
      "new loss: 0.16221829012116193\n",
      "Found Rho=1.794196118391565, after 60 steps\n",
      "Fitting model nº31\n",
      "Current loss: 0.16808834123223523\n",
      "new loss: 0.16222844653409102\n",
      "Found Rho=1.6803140521915254, after 56 steps\n",
      "Fitting model nº32\n",
      "Current loss: 0.1673797022003407\n",
      "new loss: 0.16223924463494624\n",
      "Found Rho=1.595268824813938, after 53 steps\n",
      "Fitting model nº33\n",
      "Current loss: 0.16676208438075066\n",
      "new loss: 0.16224830292130096\n",
      "Found Rho=1.5091273728364991, after 50 steps\n",
      "Fitting model nº34\n",
      "Current loss: 0.16622486420063504\n",
      "new loss: 0.1622556001354566\n",
      "Found Rho=1.4220333663968718, after 47 steps\n",
      "Fitting model nº35\n",
      "Current loss: 0.16575856144320997\n",
      "new loss: 0.16226143285457234\n",
      "Found Rho=1.3341129557188418, after 44 steps\n",
      "Fitting model nº36\n",
      "Current loss: 0.16535474193118083\n",
      "new loss: 0.16226871728169184\n",
      "Found Rho=1.2760626381258848, after 42 steps\n",
      "Fitting model nº37\n",
      "Current loss: 0.1649976996113081\n",
      "new loss: 0.16227210964258346\n",
      "Found Rho=1.1869033304999976, after 39 steps\n",
      "Fitting model nº38\n",
      "Current loss: 0.1646902019247717\n",
      "new loss: 0.16227693208878663\n",
      "Found Rho=1.1278514057908977, after 37 steps\n",
      "Fitting model nº39\n",
      "Current loss: 0.16441913695331986\n",
      "new loss: 0.16228096206512851\n",
      "Found Rho=1.0684330188036957, after 35 steps\n",
      "Fitting model nº40\n",
      "Current loss: 0.16418065829872014\n",
      "new loss: 0.16228422526245784\n",
      "Found Rho=1.0086894234902002, after 33 steps\n",
      "Fitting model nº41\n",
      "Current loss: 0.1639712929912996\n",
      "new loss: 0.1622868585186058\n",
      "Found Rho=0.9486577118554476, after 31 steps\n",
      "Fitting model nº42\n",
      "Current loss: 0.16378791121155342\n",
      "new loss: 0.16229123000268414\n",
      "Found Rho=0.9191438125399624, after 30 steps\n",
      "Fitting model nº43\n",
      "Current loss: 0.16362234651766272\n",
      "new loss: 0.16229248026697168\n",
      "Found Rho=0.8586868726977797, after 28 steps\n",
      "Fitting model nº44\n",
      "Current loss: 0.16347811625942335\n",
      "new loss: 0.1622960853366855\n",
      "Found Rho=0.8288388442407107, after 27 steps\n",
      "Fitting model nº45\n",
      "Current loss: 0.16334819423262223\n",
      "new loss: 0.16229625403208248\n",
      "Found Rho=0.7680376919372703, after 25 steps\n",
      "Fitting model nº46\n",
      "Current loss: 0.16323572893614924\n",
      "new loss: 0.16229873635499079\n",
      "Found Rho=0.7379196914860472, after 24 steps\n",
      "Fitting model nº47\n",
      "Current loss: 0.16313466910526916\n",
      "new loss: 0.16230111123791027\n",
      "Found Rho=0.7077094938356279, after 23 steps\n",
      "Fitting model nº48\n",
      "Current loss: 0.16304402635849713\n",
      "new loss: 0.16230016718137055\n",
      "Found Rho=0.6465313356807139, after 21 steps\n",
      "Fitting model nº49\n",
      "Current loss: 0.16296646593904834\n",
      "new loss: 0.1623014499621024\n",
      "Found Rho=0.6161223566931048, after 20 steps\n",
      "Fitting model nº50\n",
      "Current loss: 0.16289711173109112\n",
      "new loss: 0.16230251780014238\n",
      "Found Rho=0.58564681988502, after 19 steps\n",
      "Fitting model nº51\n",
      "Current loss: 0.16283522509587778\n",
      "new loss: 0.16230336079379518\n",
      "Found Rho=0.5551105399559497, after 18 steps\n",
      "Fitting model nº52\n",
      "Current loss: 0.16278012471716782\n",
      "new loss: 0.16230399251262034\n",
      "Found Rho=0.5245189403678739, after 17 steps\n",
      "Fitting model nº53\n",
      "Current loss: 0.1627311831711977\n",
      "new loss: 0.16230444981040273\n",
      "Found Rho=0.49387709054279144, after 16 steps\n",
      "Fitting model nº54\n",
      "Current loss: 0.16268782375188956\n",
      "new loss: 0.16230740315886455\n",
      "Found Rho=0.49413662546380327, after 16 steps\n",
      "Fitting model nº55\n",
      "Current loss: 0.16264703857780355\n",
      "new loss: 0.1623073233625144\n",
      "Found Rho=0.4634295824029227, after 15 steps\n",
      "Fitting model nº56\n",
      "Current loss: 0.16261110887415628\n",
      "new loss: 0.16230709212721223\n",
      "Found Rho=0.432682288249275, after 14 steps\n",
      "Fitting model nº57\n",
      "Current loss: 0.1625795582654411\n",
      "new loss: 0.16230681520677337\n",
      "Found Rho=0.40189887047246486, after 13 steps\n",
      "Fitting model nº58\n",
      "Current loss: 0.16255195238580075\n",
      "new loss: 0.16230925939962323\n",
      "Found Rho=0.40206063686038895, after 13 steps\n",
      "Fitting model nº59\n",
      "Current loss: 0.16252594995355307\n",
      "new loss: 0.16230843387413108\n",
      "Found Rho=0.37123097805830035, after 12 steps\n",
      "Fitting model nº60\n",
      "Current loss: 0.1625033557326832\n",
      "new loss: 0.1623077448423601\n",
      "Found Rho=0.34037325116807926, after 11 steps\n",
      "Fitting model nº61\n",
      "Current loss: 0.162483817445593\n",
      "new loss: 0.16230961604488003\n",
      "Found Rho=0.3404850934674928, after 11 steps\n",
      "Fitting model nº62\n",
      "Current loss: 0.16246538595280152\n",
      "new loss: 0.16230854077147677\n",
      "Found Rho=0.30959178890001815, after 10 steps\n",
      "Fitting model nº63\n",
      "Current loss: 0.16244958220832542\n",
      "new loss: 0.16231036554947223\n",
      "Found Rho=0.3096822852048498, after 10 steps\n",
      "Fitting model nº64\n",
      "Current loss: 0.16243467374644682\n",
      "new loss: 0.16230900856810843\n",
      "Found Rho=0.2787583982178884, after 9 steps\n",
      "Fitting model nº65\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current loss: 0.1624220157675988\n",
      "new loss: 0.16231063112277516\n",
      "Found Rho=0.2788303443156578, after 9 steps\n",
      "Fitting model nº66\n",
      "Current loss: 0.16241006893388038\n",
      "new loss: 0.1623091410745825\n",
      "Found Rho=0.24788050560147326, after 8 steps\n",
      "Fitting model nº67\n",
      "Current loss: 0.16240004262373955\n",
      "new loss: 0.16231044950016052\n",
      "Found Rho=0.24793644055721104, after 8 steps\n",
      "Fitting model nº68\n",
      "Current loss: 0.162390568410029\n",
      "Converged, loss improvement: 9.474213710558566e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|██████████████████████████████████████████████████████████████████▍                | 4/5 [10:08<02:31, 151.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting model nº1\n",
      "Current loss: 0.7969012322386521\n",
      "new loss: 0.22766971560467067\n",
      "Found Rho=27.521099998559745, after 10383 steps\n",
      "Fitting model nº2\n",
      "Current loss: 0.7309182919749396\n",
      "new loss: 0.23229306725475568\n",
      "Found Rho=23.151692560809934, after 7224 steps\n",
      "Fitting model nº3\n",
      "Current loss: 0.6737967420483533\n",
      "new loss: 0.21173869023038344\n",
      "Found Rho=20.53552125486003, after 5163 steps\n",
      "Fitting model nº4\n",
      "Current loss: 0.6185844646350287\n",
      "new loss: 0.20448800681240004\n",
      "Found Rho=17.82169539000102, after 3541 steps\n",
      "Fitting model nº5\n",
      "Current loss: 0.5662073878316399\n",
      "new loss: 0.19455182575642138\n",
      "Found Rho=15.680228526808255, after 2484 steps\n",
      "Fitting model nº6\n",
      "Current loss: 0.5160157157021649\n",
      "new loss: 0.1878365721664937\n",
      "Found Rho=13.775584968304358, after 1755 steps\n",
      "Fitting model nº7\n",
      "Current loss: 0.4686652671329751\n",
      "new loss: 0.18328064110619327\n",
      "Found Rho=12.122718962560258, after 1260 steps\n",
      "Fitting model nº8\n",
      "Current loss: 0.42479933768666167\n",
      "new loss: 0.18017233102381794\n",
      "Found Rho=10.69833102173815, after 924 steps\n",
      "Fitting model nº9\n",
      "Current loss: 0.3850141622101662\n",
      "new loss: 0.17803885163223135\n",
      "Found Rho=9.50243583489126, after 696 steps\n",
      "Fitting model nº10\n",
      "Current loss: 0.34965841904776934\n",
      "new loss: 0.17656063095187\n",
      "Found Rho=8.495801542862187, after 539 steps\n",
      "Fitting model nº11\n",
      "Current loss: 0.31889906075454444\n",
      "new loss: 0.17552643585817462\n",
      "Found Rho=7.645194545289339, after 429 steps\n",
      "Fitting model nº12\n",
      "Current loss: 0.29268345129634105\n",
      "new loss: 0.17479563903075562\n",
      "Found Rho=6.935166298972884, after 351 steps\n",
      "Fitting model nº13\n",
      "Current loss: 0.2707136950929138\n",
      "new loss: 0.1742729334496971\n",
      "Found Rho=6.350066626844134, after 295 steps\n",
      "Fitting model nº14\n",
      "Current loss: 0.25252862566341566\n",
      "new loss: 0.17389349792576725\n",
      "Found Rho=5.842136150929692, after 253 steps\n",
      "Fitting model nº15\n",
      "Current loss: 0.2376702807081606\n",
      "new loss: 0.17361541662243107\n",
      "Found Rho=5.428324563321812, after 222 steps\n",
      "Fitting model nº16\n",
      "Current loss: 0.2255803253749362\n",
      "new loss: 0.17340763315567576\n",
      "Found Rho=5.04496356003714, after 197 steps\n",
      "Fitting model nº17\n",
      "Current loss: 0.2158396248532875\n",
      "new loss: 0.173251602702133\n",
      "Found Rho=4.731972465697239, after 178 steps\n",
      "Fitting model nº18\n",
      "Current loss: 0.20797412659078499\n",
      "new loss: 0.17313183646051342\n",
      "Found Rho=4.438189486362739, after 162 steps\n",
      "Fitting model nº19\n",
      "Current loss: 0.20164960088082715\n",
      "new loss: 0.17303927299659294\n",
      "Found Rho=4.1824036149632215, after 149 steps\n",
      "Fitting model nº20\n",
      "Current loss: 0.19654946900922307\n",
      "new loss: 0.17296657507683458\n",
      "Found Rho=3.9505073917200297, after 138 steps\n",
      "Fitting model nº21\n",
      "Current loss: 0.19242802600595454\n",
      "new loss: 0.17290904688499184\n",
      "Found Rho=3.7524689876827746, after 129 steps\n",
      "Fitting model nº22\n",
      "Current loss: 0.18907595052036344\n",
      "new loss: 0.172861960070067\n",
      "Found Rho=3.5361751529427345, after 120 steps\n",
      "Fitting model nº23\n",
      "Current loss: 0.18636496354156\n",
      "new loss: 0.17282431259056782\n",
      "Found Rho=3.3655579564705054, after 113 steps\n",
      "Fitting model nº24\n",
      "Current loss: 0.18414387124766496\n",
      "new loss: 0.17279290069074915\n",
      "Found Rho=3.1847025051824454, after 106 steps\n",
      "Fitting model nº25\n",
      "Current loss: 0.18232846985618492\n",
      "new loss: 0.17276703197097756\n",
      "Found Rho=3.026182256269193, after 100 steps\n",
      "Fitting model nº26\n",
      "Current loss: 0.18083253443080613\n",
      "new loss: 0.17274561552217887\n",
      "Found Rho=2.8922836993672902, after 95 steps\n",
      "Fitting model nº27\n",
      "Current loss: 0.17958827325282706\n",
      "new loss: 0.17272725077316808\n",
      "Found Rho=2.7538942525992987, after 90 steps\n",
      "Fitting model nº28\n",
      "Current loss: 0.17855355059544092\n",
      "new loss: 0.17271134378556277\n",
      "Found Rho=2.6118552412557627, after 85 steps\n",
      "Fitting model nº29\n",
      "Current loss: 0.17769286952362937\n",
      "new loss: 0.17269821716163553\n",
      "Found Rho=2.497876243078114, after 81 steps\n",
      "Fitting model nº30\n",
      "Current loss: 0.17696814829210936\n",
      "new loss: 0.17268605019876912\n",
      "Found Rho=2.3506484978409703, after 76 steps\n",
      "Fitting model nº31\n",
      "Current loss: 0.17636508517024466\n",
      "new loss: 0.1726765873522923\n",
      "Found Rho=2.2637540257635953, after 73 steps\n",
      "Fitting model nº32\n",
      "Current loss: 0.17584957220661243\n",
      "new loss: 0.17266753881761754\n",
      "Found Rho=2.144398606454112, after 69 steps\n",
      "Fitting model nº33\n",
      "Current loss: 0.17541468608418098\n",
      "new loss: 0.17266023496608032\n",
      "Found Rho=2.055097868567709, after 66 steps\n",
      "Fitting model nº34\n",
      "Current loss: 0.17504223516741793\n",
      "new loss: 0.1726529777726894\n",
      "Found Rho=1.9336421101477184, after 62 steps\n",
      "Fitting model nº35\n",
      "Current loss: 0.1747279168425633\n",
      "new loss: 0.17264713065731846\n",
      "Found Rho=1.8426816843894274, after 59 steps\n",
      "Fitting model nº36\n",
      "Current loss: 0.17445822504116784\n",
      "new loss: 0.1726418928990443\n",
      "Found Rho=1.7511306518537613, after 56 steps\n",
      "Fitting model nº37\n",
      "Current loss: 0.17422674236832467\n",
      "new loss: 0.17263777805958103\n",
      "Found Rho=1.6904683801734646, after 54 steps\n",
      "Fitting model nº38\n",
      "Current loss: 0.1740244368081115\n",
      "new loss: 0.17263337798090603\n",
      "Found Rho=1.5980537880987573, after 51 steps\n",
      "Fitting model nº39\n",
      "Current loss: 0.17385087648668626\n",
      "new loss: 0.17263011221346328\n",
      "Found Rho=1.5367046281258063, after 49 steps\n",
      "Fitting model nº40\n",
      "Current loss: 0.17369903102670525\n",
      "new loss: 0.17262638983628611\n",
      "Found Rho=1.4436599928560072, after 46 steps\n",
      "Fitting model nº41\n",
      "Current loss: 0.17356890303982228\n",
      "new loss: 0.17262365289719714\n",
      "Found Rho=1.3818104938851998, after 44 steps\n",
      "Fitting model nº42\n",
      "Current loss: 0.17345497318993258\n",
      "new loss: 0.17262116325966614\n",
      "Found Rho=1.3197813272713146, after 42 steps\n",
      "Fitting model nº43\n",
      "Current loss: 0.17335525457687015\n",
      "new loss: 0.1726188717308748\n",
      "Found Rho=1.2575961708705796, after 40 steps\n",
      "Fitting model nº44\n",
      "Current loss: 0.17326801065770506\n",
      "new loss: 0.17261674971021226\n",
      "Found Rho=1.195275506663523, after 38 steps\n",
      "Fitting model nº45\n",
      "Current loss: 0.17319172284647882\n",
      "new loss: 0.1726147882690247\n",
      "Found Rho=1.1328370821168816, after 36 steps\n",
      "Fitting model nº46\n",
      "Current loss: 0.17312506248560391\n",
      "new loss: 0.17261299763060362\n",
      "Found Rho=1.070296305610403, after 34 steps\n",
      "Fitting model nº47\n",
      "Current loss: 0.17306686662630832\n",
      "new loss: 0.17261193105658867\n",
      "Found Rho=1.0391935086603572, after 33 steps\n",
      "Fitting model nº48\n",
      "Current loss: 0.1730145916306352\n",
      "new loss: 0.17261029608814227\n",
      "Found Rho=0.9765036402601336, after 31 steps\n",
      "Fitting model nº49\n",
      "Current loss: 0.17296908849221992\n",
      "new loss: 0.17260945599347471\n",
      "Found Rho=0.9452845607652028, after 30 steps\n",
      "Fitting model nº50\n",
      "Current loss: 0.1729282297670766\n",
      "new loss: 0.17260797546994672\n",
      "Found Rho=0.8824777061882187, after 28 steps\n",
      "Fitting model nº51\n",
      "Current loss: 0.17289279572827557\n",
      "new loss: 0.17260723267880293\n",
      "Found Rho=0.8511676373537821, after 27 steps\n",
      "Fitting model nº52\n",
      "Current loss: 0.1728609974090747\n",
      "new loss: 0.1726059868855326\n",
      "Found Rho=0.7882691162826765, after 25 steps\n",
      "Fitting model nº53\n",
      "Current loss: 0.1728335508221918\n",
      "new loss: 0.17260529390192722\n",
      "Found Rho=0.7568879134726115, after 24 steps\n",
      "Fitting model nº54\n",
      "Current loss: 0.1728089428210624\n",
      "new loss: 0.17260466854137407\n",
      "Found Rho=0.7254826326149137, after 23 steps\n",
      "Fitting model nº55\n",
      "Current loss: 0.17278690553168288\n",
      "new loss: 0.17260409243385955\n",
      "Found Rho=0.6940555660607809, after 22 steps\n",
      "Fitting model nº56\n",
      "Current loss: 0.17276719522705744\n",
      "new loss: 0.17260355181718473\n",
      "Found Rho=0.6626087945925033, after 21 steps\n",
      "Fitting model nº57\n",
      "Current loss: 0.17274959015780753\n",
      "new loss: 0.17260303741610197\n",
      "Found Rho=0.6311442099163552, after 20 steps\n",
      "Fitting model nº58\n",
      "Current loss: 0.17273388860431318\n",
      "new loss: 0.17260254435754352\n",
      "Found Rho=0.5996635348511494, after 19 steps\n",
      "Fitting model nº59\n",
      "Current loss: 0.17271990712815802\n",
      "new loss: 0.17260207212053028\n",
      "Found Rho=0.5681683414746962, after 18 steps\n",
      "Fitting model nº60\n",
      "Current loss: 0.17270747900298716\n",
      "new loss: 0.17260162451981137\n",
      "Found Rho=0.5366600674624301, after 17 steps\n",
      "Fitting model nº61\n",
      "Current loss: 0.17269645280699192\n",
      "new loss: 0.17260120972270637\n",
      "Found Rho=0.5051400308276466, after 16 steps\n",
      "Fitting model nº62\n",
      "Current loss: 0.17268669116114194\n",
      "Converged, loss improvement: 9.761645849981626e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [12:16<00:00, 144.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation accuracy: 0.89\n"
     ]
    }
   ],
   "source": [
    "# Create the model\n",
    "base_tree = DecisionTreeRegressor(max_depth=3)\n",
    "boosted_trees = GradientBoostingClassifier(base_tree, learning_rate=0.05, max_models=100)\n",
    "\n",
    "# Validate\n",
    "acc = cross_validate(boosted_trees, 5)\n",
    "print(\"Cross-Validation accuracy: %.2f\" % acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
